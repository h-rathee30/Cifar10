# IMPORT OF LIBRARIES AND MODULES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD, Adam
import seaborn as sns

# Load the data and turn the target values as categorical
def Load_data():
  (x_1,y_1),(x_2,y_2) = cifar10.load_data()
  y_1 = keras.utils.to_categorical(y_1)
  y_2 = keras.utils.to_categorical(y_2)
  return x_1, x_2, y_1, y_2
  
  # Change data type to float and normalize between [0,1]
def Process_pixel(x_train, x_test):
  x_train = x_train.astype('float32')
  x_test = x_test.astype('float32')
  x_train = x_train/255.0
  x_test = x_test/255.0
  return x_train, x_test
  
  # Build a 3 block VGG style architecture 32, 64, 128 units respectively
def define_model():
  model = Sequential()
  # Feature Detector part of the model
  model.add(Conv2D( 32, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu', input_shape = (32,32,3) ) )
  model.add(Conv2D( 32, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu' ) )
  model.add(BatchNormalization())
  model.add(MaxPooling2D(2,2))
  model.add(Dropout(0.2))
  model.add(Conv2D( 64, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu' ) )
  model.add(BatchNormalization())
  model.add(Conv2D( 64, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu' ) )
  model.add(BatchNormalization())
  model.add(MaxPooling2D(2,2))
  model.add(Dropout(0.3))
  model.add(Conv2D( 128, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu' ) )
  model.add(BatchNormalization())
  model.add(Conv2D( 128, (3,3), kernel_initializer='he_uniform', padding= 'same', activation= 'relu' ) )
  model.add(BatchNormalization())
  model.add(MaxPooling2D(2,2))
  model.add(Dropout(0.4))
  model.add(Flatten())
  # Fully connected Hidden Layer
  model.add(Dense( 128, kernel_initializer='he_uniform', activation= 'relu' ) )
  model.add(Dropout(0.5))
  model.add(Dense(10, activation= 'softmax'))
  opt = SGD(lr= 0.001, momentum= 0.9)
  # Compile the model
  model.compile(optimizer= opt, loss= 'categorical_crossentropy', metrics= ['accuracy'])
  return model
  
  # Plot the Learning curves
def plot_loss_accuracy(epochs_history):
  # Plot Loss
  plt.subplot(211)
  plt.title('Cross Entropy Loss')
  plt.plot(epochs_history.history['loss'], color = 'blue', label= 'train')
  plt.plot(epochs_history.history['val_loss'], color= 'orange', label= 'test')
  plt.subplot(212)
  plt.title('Classification Accuracy')
  plt.plot(epochs_history.history['accuracy'], color= 'blue', label= 'train')
  plt.plot(epochs_history.history['val_accuracy'], color= 'orange', label= 'test')
  plt.show()
  
x_train, x_test, y_train, y_test = Load_data()
x_train, x_test = Process_pixel(x_train,x_test)
model = define_model()
model.summary()
epochs_history = model.fit(x_train, y_train, epochs= 125, batch_size= 64, validation_data= (x_test, y_test), verbose= 1)
score = model.evaluate(x_test,y_test)
print('Test Accuracy : %0.4f' %(score[1]*100.0) )
# Learning curves
plot_loss_accuracy(epochs_history)
